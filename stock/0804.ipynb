{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0550e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€å°å¯è¿è¡Œé¡¹ç›®ï¼šåŸºäºLSTMçš„è‚¡ç¥¨èµ°åŠ¿é¢„æµ‹ç³»ç»Ÿ\n",
    "# æ­¥éª¤ï¼šé€‰è‚¡ + æŠ€æœ¯æŒ‡æ ‡ç”Ÿæˆ + æ»‘çª—æ ·æœ¬æ„å»º + LSTMæ¨¡å‹è®­ç»ƒ + é¢„æµ‹ + å¯è§†åŒ– + ä¹°å…¥ç­–ç•¥åˆ¤æ–­ + æ•°æ®ä¿å­˜\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import akshare as ak\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "###############################\n",
    "# ä¾èµ–æç¤ºï¼ˆä¿®å¤ micropip æŠ¥é”™ï¼‰\n",
    "###############################\n",
    "# è‹¥è¿è¡Œä¸­å‡ºç° pandas_ta æŠ¥é”™å¯ä½¿ç”¨ï¼špip install pandas-ta\n",
    "\n",
    "try:\n",
    "    import pandas_ta as ta\n",
    "except ModuleNotFoundError:\n",
    "    raise ModuleNotFoundError(\"pandas_ta æœªå®‰è£…ï¼Œè¯·è¿è¡Œ pip install pandas-ta\")\n",
    "\n",
    "\n",
    "###############################\n",
    "# 1. é€‰è‚¡é€»è¾‘ï¼šè·å–æ²ªæ·±300ä¸­å‰10åªè‚¡ç¥¨ï¼ˆæŒ‰ä»£ç æ’åºï¼‰\n",
    "###############################\n",
    "\n",
    "stocks = ak.index_stock_cons(symbol=\"000300\")\n",
    "stocks = stocks.sort_values(\"ä»£ç \").reset_index(drop=True)\n",
    "selected_codes = list(stocks.loc[:9, 'ä»£ç '])\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "\n",
    "###############################\n",
    "# 2. è·å–æ•°æ® + ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡ + ä¿å­˜CSV\n",
    "###############################\n",
    "\n",
    "def fetch_and_process(code):\n",
    "    df = ak.stock_zh_a_hist(symbol=code, period=\"daily\", start_date=\"20220101\", adjust=\"qfq\")\n",
    "    df = df.rename(columns={\"æ—¥æœŸ\": \"date\", \"å¼€ç›˜\": \"open\", \"æ”¶ç›˜\": \"close\", \"æœ€é«˜\": \"high\", \"æœ€ä½\": \"low\", \"æˆäº¤é‡\": \"volume\"})\n",
    "    df['code'] = code\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values('date')\n",
    "\n",
    "    df.ta.sma(length=5, append=True)\n",
    "    df.ta.rsi(length=14, append=True)\n",
    "    df.ta.macd(append=True)\n",
    "\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    df.to_csv(f\"data/{code}_features.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    return df\n",
    "\n",
    "stock_dfs = [fetch_and_process(code) for code in selected_codes]\n",
    "data = pd.concat(stock_dfs)\n",
    "\n",
    "\n",
    "###############################\n",
    "# 3. æ„å»ºæ»‘åŠ¨çª—å£æ ·æœ¬ï¼ˆ10å¤©é¢„æµ‹1å¤©ï¼‰\n",
    "###############################\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, df, seq_len=10):\n",
    "        features = ['close', 'SMA_5', 'RSI_14', 'MACD_12_26_9']\n",
    "        df = df.copy()\n",
    "        scaler = MinMaxScaler()\n",
    "        df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "        self.x, self.y_cls, self.y_reg, self.last_close = [], [], [], []\n",
    "\n",
    "        for _, stock in df.groupby('code'):\n",
    "            stock = stock.reset_index(drop=True)\n",
    "            for i in range(len(stock) - seq_len - 1):\n",
    "                window = stock.iloc[i:i+seq_len]\n",
    "                target = stock.iloc[i+seq_len]\n",
    "                delta = (target['close'] - stock.iloc[i+seq_len-1]['close']) / stock.iloc[i+seq_len-1]['close']\n",
    "\n",
    "                self.x.append(window[features].values)\n",
    "                self.y_reg.append(delta)\n",
    "                self.y_cls.append(1 if delta > 0 else 0)\n",
    "                self.last_close.append(stock.iloc[i+seq_len-1]['close'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.x[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.y_cls[idx], dtype=torch.long),\n",
    "            torch.tensor(self.y_reg[idx], dtype=torch.float32),\n",
    "            self.last_close[idx]\n",
    "        )\n",
    "\n",
    "dataset = StockDataset(data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32)\n",
    "\n",
    "\n",
    "###############################\n",
    "# 4. æ„å»º LSTM æ¨¡å‹\n",
    "###############################\n",
    "class StockLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_cls = nn.Linear(hidden_dim, 2)\n",
    "        self.fc_reg = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        return self.fc_cls(out), self.fc_reg(out).squeeze()\n",
    "\n",
    "model = StockLSTM(input_dim=4, hidden_dim=64)\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_reg = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "###############################\n",
    "# 5. è®­ç»ƒæ¨¡å‹\n",
    "###############################\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y_cls, y_reg, _ in train_loader:\n",
    "        out_cls, out_reg = model(x)\n",
    "        loss = criterion_cls(out_cls, y_cls) + criterion_reg(out_reg, y_reg)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "\n",
    "###############################\n",
    "# 6. è¯„ä¼° + å¯è§†åŒ– + ä¹°å…¥å»ºè®®\n",
    "###############################\n",
    "model.eval()\n",
    "y_true_cls, y_pred_cls = [], []\n",
    "y_true_reg, y_pred_reg = [], []\n",
    "last_closes, predicted_deltas = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y_cls, y_reg, last_close in test_loader:\n",
    "        out_cls, out_reg = model(x)\n",
    "        y_true_cls += y_cls.tolist()\n",
    "        y_pred_cls += out_cls.argmax(dim=1).tolist()\n",
    "        y_true_reg += y_reg.tolist()\n",
    "        y_pred_reg += out_reg.tolist()\n",
    "        last_closes += last_close\n",
    "        predicted_deltas += out_reg.tolist()\n",
    "\n",
    "acc = accuracy_score(y_true_cls, y_pred_cls)\n",
    "print(f\"åˆ†ç±»å‡†ç¡®ç‡: {acc:.4f}\")\n",
    "\n",
    "rmse = mean_squared_error(y_true_reg, y_pred_reg, squared=False)\n",
    "print(f\"å›å½’RMSE: {rmse:.4f}\")\n",
    "\n",
    "plt.plot(y_true_reg[:100], label=\"True\")\n",
    "plt.plot(y_pred_reg[:100], label=\"Pred\")\n",
    "plt.title(\"æœªæ¥1æ—¥æ”¶ç›Šç‡é¢„æµ‹\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“ˆ ä¹°å…¥å»ºè®®åˆ¤æ–­ï¼š\")\n",
    "threshold = 0.01\n",
    "for i in range(len(predicted_deltas)):\n",
    "    flag = \"âœ… ä¹°å…¥\" if predicted_deltas[i] > threshold else \"âŒ è§‚æœ›\"\n",
    "    print(f\"æ ·æœ¬{i}: é¢„æµ‹æ¶¨å¹… {predicted_deltas[i]*100:.2f}%ï¼Œå»ºè®®ï¼š{flag}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
